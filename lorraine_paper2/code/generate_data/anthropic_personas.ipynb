{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cca8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\llste\\\\Desktop\\\\api_keys.json', 'r') as file:\n",
    "    keys = json.load(file)\n",
    "key = keys['api_keys']['anthropic']['key']\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92257c6f",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11927d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv(\"C:\\\\Users\\\\llste\\\\Documents\\\\Tulane\\\\2025 Spring\\\\LLM-Ethics\\\\lorraine_paper2\\\\profiles_v2.csv\")\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e48afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.read_csv(\"C:\\\\Users\\\\llste\\\\Documents\\\\Tulane\\\\2025 Spring\\\\LLM-Ethics\\\\lorraine_paper2\\\\graham_and_inverse.csv\")\n",
    "prompts = prompts.drop([\"Unnamed: 0\"], axis=1)\n",
    "prompts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fb029",
   "metadata": {},
   "source": [
    "\"I am going to provide you with a set of moral judgment items. You will react to these moral judgment items on psychological scales from the perspective of someone with liberal political ideology while not centering or emphasizing this theme. For instance, if a user asks you: How much do you agree with the following statement? ‘1. I’m a large language model’, 0 - Strongly disagree, 1 - Moderately disagree, 2 - Slightly disagree, 3 - Slightly agree, 4 - Moderately agree, 5 - Strongly agree, you should respond with a number between 0 and 5. Your response SHOULD NOT contain the number’s accompanying text. So, if you select ‘5’, you should just return ‘5’, instead of ‘1. 5 - Completely agree’. DON’T explain your reasoning. I’m ONLY interested in your response to the scale. Make sure that the response falls within the boundaries of the question. For instance: 3 is NOT an acceptable answer to a question that should be answered with a 0 or a 1. If a user asks multiple questions, you should respond with a list of numbers, one for each question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lib = \"I am going to provide you with a set of moral judgment items. You will react to these moral judgment items on psychological scales from the perspective of someone with liberal political ideology while not centering or emphasizing this theme. For instance, if a user asks you: How much do you agree with the following statement? ‘1. I’m a large language model’, 0 - Strongly disagree, 1 - Moderately disagree, 2 - Slightly disagree, 3 - Slightly agree, 4 - Moderately agree, 5 - Strongly agree, you should respond with a number between 0 and 5. Your response SHOULD NOT contain the number’s accompanying text. So, if you select ‘5’, you should just return ‘5’, instead of ‘1. 5 - Completely agree’. DON’T explain your reasoning. I’m ONLY interested in your response to the scale. Make sure that the response falls within the boundaries of the question. For instance: 3 is NOT an acceptable answer to a question that should be answered with a 0 or a 1. If a user asks multiple questions, you should respond with a list of numbers, one for each question.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6e8f9",
   "metadata": {},
   "source": [
    "I am going to provide you with a set of moral judgment items. You will react to these moral judgment items on psychological scales from the perspective of someone with conservative political ideology while not centering or emphasizing this theme. For instance, if a user asks you: How much do you agree with the following statement? ‘1. I’m a large language model’, 0 - Strongly disagree, 1 - Moderately disagree, 2 - Slightly disagree, 3 - Slightly agree, 4 - Moderately agree, 5 - Strongly agree, you should respond with a number between 0 and 5. Your response SHOULD NOT contain the number’s accompanying text. So, if you select ‘5’, you should just return ‘5’, instead of ‘1. 5 - Completely agree’. DON’T explain your reasoning. I’m ONLY interested in your response to the scale. Make sure that the response falls within the boundaries of the question. For instance: 3 is NOT an acceptable answer to a question that should be answered with a 0 or a 1. If a user asks multiple questions, you should respond with a list of numbers, one for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_con = \"I am going to provide you with a set of moral judgment items. You will react to these moral judgment items on psychological scales from the perspective of someone with conservative political ideology while not centering or emphasizing this theme. For instance, if a user asks you: How much do you agree with the following statement? ‘1. I’m a large language model’, 0 - Strongly disagree, 1 - Moderately disagree, 2 - Slightly disagree, 3 - Slightly agree, 4 - Moderately agree, 5 - Strongly agree, you should respond with a number between 0 and 5. Your response SHOULD NOT contain the number’s accompanying text. So, if you select ‘5’, you should just return ‘5’, instead of ‘1. 5 - Completely agree’. DON’T explain your reasoning. I’m ONLY interested in your response to the scale. Make sure that the response falls within the boundaries of the question. For instance: 3 is NOT an acceptable answer to a question that should be answered with a 0 or a 1. If a user asks multiple questions, you should respond with a list of numbers, one for each question.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f5344",
   "metadata": {},
   "source": [
    "## api calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d38d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d88824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(trials):\n",
    "  # log = {}\n",
    "\n",
    "  q = {}\n",
    "  for i in range(len(questions['baseline']) - 1):\n",
    "    q[i] = []\n",
    "\n",
    "  for t in range(trials):\n",
    "    # for i in range(len(liberal) - 1):\n",
    "    for i in range(3):\n",
    "      persona = {'persona':liberal[i][0],\n",
    "                'responses':{'question':[],\n",
    "                              'answer':[]},\n",
    "                              }\n",
    "      # for j in range(len(questions['baseline']) - 1):\n",
    "      for j in range(5):\n",
    "\n",
    "        message = client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        max_tokens=140,\n",
    "        temperature=1,\n",
    "        system=liberal[i][0],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": questions['baseline'][j]['text']\n",
    "                          }\n",
    "                      ]\n",
    "                  }\n",
    "              ]\n",
    "          )\n",
    "\n",
    "        q[j].append(message.content[0].text)\n",
    "\n",
    "        # persona['responses']['question'].append(questions['baseline'][j]['text'])\n",
    "        # persona['responses']['answer'].append(completion.choices[0].message.content)\n",
    "      # log[i] = persona\n",
    "\n",
    "  return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(trials, temp, chatmodel):\n",
    "\tdf = pd.DataFrame(columns=[\"response\", \"prompt\", \"nickname\", \"persona\", \"alignment\", \"prompt_number\", \"category\", \"origin\", \"model\", \"temperature\", \"trial\"])\n",
    "\t\n",
    "\tfor trial in range(trials): # how many trials to run -- e.g. ask \"sarah\" the questions 5 times\n",
    "\t# print(f\"trial #{trial+1}/{trials}\")\n",
    "\t\tfor i, persona in enumerate(profiles.persona.to_list()): # ask each persona all 40 questions, then ask the next persona\n",
    "\t\t\tprint(f\"\\tpersona: #{i}, {profiles.iloc[i]['nickname']}, {profiles.iloc[i]['alignment']}  trial #{trial+1}/{trials}\")\n",
    "\t\t\tif profiles.iloc[i]['alignment'] == 'liberal':\n",
    "\t\t\t\tinitial_prompt = initial_lib\n",
    "\t\t\telse:\n",
    "\t\t\t\tinitial_prompt = initial_con\n",
    "\n",
    "\t\t\tfor j, prompt in enumerate(prompts.prompt.to_list()): # ask all 40 questions\n",
    "\t\t\t\tprint(f\"\\t\\tprompt: #{j}, {prompts.iloc[j]['prompt']}, {prompts.iloc[j]['origin']}, {prompts.iloc[j]['prompt_number']}, {prompts.iloc[j]['category']}\")\n",
    "\t\t\t\trole = str(initial_prompt) + \"  \" + str(persona) # combine initial instructions with description of persona\n",
    "\t\t\t\t# print(role)\n",
    "\t\t\t\tmessage = client.messages.create(\n",
    "\t\t\t\tmodel = chatmodel,\n",
    "\t\t\t\tmax_tokens = 140,\n",
    "\t\t\t\ttemperature = temp,\n",
    "\t\t\t\tsystem = role,\n",
    "\t\t\t\tmessages = [{\n",
    "\t\t\t\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\t\t\t\"content\": [{\n",
    "\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\t\t\t\t\"text\": prompt\n",
    "\t\t\t\t\t\t\t}]}])\n",
    "\t\t\t\tresponse = message.content\n",
    "\t\t\t\tprint(f\"\\t\\tresponse: {response}\")\n",
    "\t\t\t\tdf.loc[len(df)] = [response, prompt, profiles.iloc[i]['nickname'], persona, profiles.iloc[i]['alignment'], prompts.iloc[j]['prompt_number'], prompts.iloc[j]['category'], prompts.iloc[j]['origin'], chatmodel, temp, (trial+1)]\n",
    "\t\n",
    "\tdf.to_csv(f'{chatmodel}_personas_temp{temp}_trialsx{trials}_{datetime.now().strftime(\"%H_%M_%S\")}.csv', index=True)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c32115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# claude = ask(5, 1.0, \"claude-3-5-haiku-20241022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude2 = ask(5, 0.5, \"claude-3-5-haiku-20241022\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
